# Reading Materials
[**Paging: Introduction**](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/vm-paging.pdf)
[**Paging: Faster Translations (TLBs)**](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/vm-tlbs.pdf)
[**Paging: Smaller Tables**](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/vm-smalltables.pdf)

----
# Paging: Introduction
### Two Approaches to Space Management
- **Variable-Sized Allocation (Segmentation):**
    - Divides memory into **variable-sized segments** (e.g., code, heap, stack).
    - **Problem:** This approach can lead to **external fragmentation**, making memory allocation harder over time as free space becomes non-contiguous.
- **Fixed-Sized Allocation (Paging):**
    - **Paging** is the second approach that solves space management problems by dividing memory into **fixed-sized pieces**.
    - Paging avoids fragmentation by dividing both virtual and physical memory into **fixed-sized units**.
### Introduction to Paging
- **Basic Idea:**
    - Paging divides a process's **virtual address space** into **fixed-size units** called **pages**.
    - Correspondingly, **physical memory** is divided into **page frames**, each of which can hold a single virtual page.
- **Key Terms:**
    - **Page:** A fixed-sized block of virtual memory.
    - **Page Frame:** A fixed-sized block of physical memory.
### CRUX: How to Virtualize Memory with Pages
- The challenge in paging is to efficiently manage the mapping between **virtual pages** and **physical page frames**.
- The OS must ensure that paging **minimizes overhead** in both **space** (memory usage for tracking pages) and **time** (time taken to translate virtual addresses to physical addresses).
-----
## 18.1 - A Simple Example And Overview
### Paging Process
- **Advantages of Paging:**
    - **Flexibility:** Pages from the virtual address space can be placed in any available page frame in physical memory, without assumptions about memory layout.
    - **Simplified Memory Management:** OS keeps a list of free page frames and allocates any available frames as needed.
- **Page Table:**  A **per-process** data structure that keeps track of where each **virtual page** is located in **physical memory**.
### Address Translation
- **Virtual Address Breakdown:** The virtual address space is 64 bytes (6 bits), so a virtual address is split into two parts:
	- **Virtual Page Number (VPN):** Top 2 bits for the page number.
	- **Offset:** Bottom 4 bits for the location within the page.
- **Example Translation:**
    - Process tries to load data from **virtual address 21**.
    - Virtual address **21** in binary is `010101`:
        - **VPN = 01** (virtual page 1).
        - **Offset = 0101** (the 5th byte in the page).
    1. The **page table** is consulted to translate VPN 1. The page table indicates that **virtual page 1** is in **physical frame 7**.
    2.  Replace VPN 1 with **PFN 7**.
    3. Combine the **PFN** and the **offset**. The result is the physical address **1110101** (decimal 117).
### Key Concepts
- **Page Table Storage:** The OS stores a page table for each process, mapping virtual pages to physical page frames.
- **Page Table Entry (PTE):** Contains information about the mapping between virtual and physical pages.
 - **Benefits of Paging**
	- **No External Fragmentation:** All pages and frames are of equal size, avoiding the fragmentation issue seen with segmentation.
	- **Simplified Allocation:** The OS allocates free page frames as needed without worrying about the size of segments or how memory grows.
----
## 18.2 - Where Are Page Tables Stored?
### Problem with Large Page Tables
- **Page tables** can become **very large**, especially for typical **32-bit address spaces** with 4KB page sizes:
    - Virtual address space splits into:
        - **20-bit Virtual Page Number (VPN)**.
        - **12-bit offset** (for 4KB pages).
    - A **20-bit VPN** means there are **2^20 (1 million) possible translations**.
    - Each **Page Table Entry (PTE)** needs **4 bytes** to store the translation and related information.
    - **Memory requirement per page table**: 4MB.
- **For 100 processes**:
    - The OS would need **400MB of memory** just for page tables.
    - This is a significant amount, even on modern systems with gigabytes of memory.
- Due to their large size, **page tables** are **not stored on-chip** in the **MMU**. Instead, they are stored in **physical memory**, which the OS manages.
- The OS may even **virtualize its own memory**, allowing page tables to be stored in **virtual memory** and even **swapped to disk** when necessary.
### Efficient Page Table Management
- As page tables are large, efficient management is required.
- While **page tables** are stored in **physical memory**, modern systems use various techniques to reduce the overhead of managing and storing page tables (e.g., hierarchical or multi-level page tables, which will be covered in future lessons).
- **Page tables** grow **very large**, especially for large address spaces.
- Storing page tables in memory for **multiple processes** can consume a significant amount of memory, requiring the OS to carefully manage page tables.
- While **modern hardware** doesn't store page tables directly on-chip, it uses **main memory** to store page tables, ensuring efficient address translation while conserving on-chip resources.
----
## 18.3 - What’s Actually In The Page Table?
- The **page table** maps **virtual addresses** (specifically, **virtual page numbers (VPNs)**) to **physical addresses** (specifically, **physical frame numbers (PFNs)**).
- **Simple Structure:** The **linear page table** is the simplest form: an **array** where the **OS indexes by the VPN** to find the **PTE** that holds the translation to the **PFN**.
### Key Contents of Page Table Entries (PTEs)
- **Valid Bit:**
    - Indicates if the translation for a page is valid.
    - Used for **sparse address spaces**: Unused pages (between code, heap, and stack) are marked invalid, avoiding unnecessary memory allocation.
    - If the process tries to access an **invalid** page, it generates a **trap to the OS**, leading to process termination.
- **Protection Bits:**
    - Define whether the page can be **read from**, **written to**, or **executed**.
    - **Access violations** generate a **trap** to the OS.
- **Present Bit:**
    - Indicates if the page is currently in **physical memory** or has been **swapped to disk**.
    - Useful for handling address spaces larger than physical memory.
- **Dirty Bit:** Tracks whether the page has been **modified** since it was loaded into memory.
- **Reference/Accessed Bit:**
    - Tracks whether a page has been **accessed**.
    - Useful in **page replacement** to identify frequently-used pages.
### Example PTE: x86 Architecture
- **x86 Page Table Entry** (PTE) contains:
    - **Present Bit (P)**: Indicates if the page is in memory.
    - **Read/Write Bit (R/W)**: Determines if the page can be written to.
    - **User/Supervisor Bit (U/S)**: Controls if user-mode processes can access the page.
    - **Cache Control Bits (PWT, PCD, PAT, G)**: Determine hardware caching behavior for the page.
    - **Accessed Bit (A)**: Tracks if the page was accessed.
    - **Dirty Bit (D)**: Tracks if the page was modified.
    - **Page Frame Number (PFN)**: Points to the actual location in physical memory.
-----
## 18.4 -  Paging: Also Too Slow
- **Translation Steps:**  When accessing memory (e.g., `movl 21, %eax`), the system must:
	1. **Translate the virtual address** (e.g., 21) to a **physical address** (e.g., 117).
	2. Fetch the corresponding **Page Table Entry (PTE)** from the page table.
	3. Use the **Virtual Page Number (VPN)** and the **Page Table Base Register** to locate the PTE.
	4. Combine the **Physical Frame Number (PFN)** and **offset** to generate the final physical address.
### Steps in Translation Process
- **VPN Extraction:**
    - Extract **VPN** from the virtual address using a **VPN mask** and shift operation.
    - For example: Virtual address `21` (binary `010101`) -> VPN = `01` (virtual page 1).
- **Address Calculation:**
    - The **PTE address** is calculated by adding the **VPN** to the **Page Table Base Register**.
    - **PFN** is extracted from the PTE, then **concatenated** with the offset to generate the final physical address.
### Performance Issue
- **Extra Memory Access:**
    - Every memory reference requires one additional memory access to retrieve the page table entry (PTE).
    - This overhead can **slow down** the system significantly, potentially by **a factor of two or more**.
- **Performance Overhead:** Paging requires extra memory references, leading to slower access times.
- **Memory Usage:** Page tables consume a large amount of memory, especially in systems with large address spaces.
-----
## 18.5 - A Memory Trace
```c
int array[1000];
...
for (i = 0; i < 1000; i++)
  array[i] = 0;
```
### Assembly Code Breakdown
- The array initialization compiles into the following assembly instructions:
    - **Instruction 1:** `movl $0x0,(%edi,%eax,4)`  
        Moves the value `0` into the array, with the base address in `%edi` and index `%eax`.
    - **Instruction 2:** `incl %eax`  
        Increments the index (`%eax`).
    - **Instruction 3:** `cmpl $0x03e8,%eax`  
        Compares `%eax` with 1000 (0x03e8 in hex).
    - **Instruction 4:** `jne 1024`  
        Jumps back to the start of the loop if the comparison shows that the loop isn’t finished.
### Virtual and Physical Address Mapping
- The system has a **64KB virtual address space** and **1KB page size**.
- The **code** resides on **virtual page 1** (1024 bytes per page) and maps to **physical frame 4**.
- The **array** spans four virtual pages (VPN 39 to VPN 42), mapping to physical frames (PFN 7 to PFN 10).
### Memory Accesses in Paging
- Each loop iteration involves **multiple memory accesses**:
    - **Instruction Fetch:** Each instruction fetch requires two memory accesses:
        1. **Page Table Access** to find the physical frame.
        2. **Instruction Fetch** from the physical memory.
    - **Array Access (movl):** This requires two more memory accesses:
        1. **Page Table Access** to translate the array’s virtual address.
        2. **Array Access** to store the value in memory.
### Visualization of Memory Accesses
![[Pasted image 20241003212844.png]]
- **Figure** shows the memory accesses for the first five iterations of the loop:
    - **10 memory accesses per iteration:**
        - 4 for instruction fetches.
        - 1 for updating the array.
        - 5 for page table accesses to perform address translation.
### Complexity of Memory Behavior
- Even for a simple loop, the memory behavior becomes complex, involving multiple virtual-to-physical address translations.
- As the loop continues to run, new memory locations (additional array elements) will be accessed, and new page table entries will be involved.
---
# Paging: Faster Translations (TLBs)
- When using paging to support virtual memory, an extra memory lookup is required for each virtual address reference, which can significantly slow down performance. To address this, hardware support in the form of a **Translation Lookaside Buffer (TLB)** is used.
	- **TLB:** A hardware cache that stores recent virtual-to-physical address translations.
	- **How it works:** On each memory reference, the system first checks the TLB for the translation. If the translation is found, the memory access proceeds quickly without consulting the page table in memory.
-----
## 19.1 - TLB Basic Algorithm
In systems with a **hardware-managed TLB** (Translation Lookaside Buffer), the process of virtual address translation is optimized to minimize memory access overhead. 
1. **Extract VPN:** The system extracts the virtual page number (VPN) from the virtual address.
2. **Check TLB:**
    - **TLB hit:** If the TLB holds the translation for the VPN, the page frame number (PFN) is retrieved, and the physical address (PA) is calculated by concatenating the PFN with the offset. This allows direct access to the memory.
    - **TLB miss:** If the TLB does not have the translation, the hardware accesses the page table in memory to find the translation.
3. **Page Table Access (on miss):** When a TLB miss occurs:
    - The hardware consults the page table to retrieve the PFN.
    - If valid, the TLB is updated with this new translation.
4. **Performance:**
    - **TLB hit:** Memory access is quick since the TLB cache is fast and located close to the CPU.
    - **TLB miss:** Extra memory lookups are required to access the page table, which incurs performance costs due to additional memory access.

- The goal is to maximize **TLB hits** to reduce the performance impact of memory accesses. 
-----
## 19.2 - Example: Accessing An Array
### Setup
- **Array Setup:** 
    - You have an array of 10 integers, each 4 bytes in size.
    - The array is located at virtual address **100**.
- **Virtual Address Space:**
    - The system uses an **8-bit virtual address space**, which means the maximum addressable memory is **256 bytes**.
    - **Page size is 16 bytes**, so virtual memory is divided into **16 pages**.
    - Virtual addresses are split into two parts:
        - **VPN (Virtual Page Number):** The top 4 bits specify the page number.
        - **Offset:** The bottom 4 bits specify the location within the page.
### Memory Layout
- **Array Layout on Virtual Pages:**
    - The array begins at **virtual address 100**, which is on page 6 (VPN = 06).
    - Since each page holds 16 bytes, and each integer is 4 bytes, only **3 integers** fit on the first page (a[0], a[1], a[2]).
    - The next integers (a[3] through a[6]) are on **page 7**.
    - The final three integers (a[7] through a[9]) are on **page 8**.
```c
int i, sum = 0;
for (i = 0; i < 10; i++) {
    sum += a[i];
}
```
### Memory Access Breakdown:
When the program runs, it makes several memory accesses. Each access involves translating a virtual address to a physical address using the TLB. Here’s a detailed breakdown:
1. **First Access (a[0]):**
    - **Virtual Address:** 100
    - **VPN:** 06 (from virtual address 100)
    - **TLB Miss:** Since this is the first access to this page, the TLB does not have the translation.
    - **Page Table Lookup:** The OS fetches the translation from the page table and loads it into the TLB.
    - **TLB Update:** The translation for VPN 06 is added to the TLB.
    - **Array Access:** The program accesses the physical memory location mapped by the TLB.
2. **Next Accesses (a[1] and a[2]):**
    - These elements are also on **VPN 06**, so the TLB hit rate is high because the translation for this page is already in the TLB.
    - **TLB Hits:** No need for further page table lookups.
    - **Array Access:** The program directly accesses the data using the TLB translation.
3. **Accessing a\[3]:**
    - **Virtual Address:** This element is on **VPN 07**, a new page.
    - **TLB Miss:** The TLB does not have the translation for this page.
    - **Page Table Lookup:** The OS fetches the translation from the page table.
    - **TLB Update:** The translation for VPN 07 is added to the TLB.
    - **Array Access:** The program accesses the element in physical memory.
4. **Next Accesses (a[4] through a[6]):**
    - These elements are also on **VPN 07**, so subsequent accesses result in **TLB hits**.
    - **TLB Hits:** No further page table lookups needed.
    - **Array Access:** The program accesses the elements directly using the TLB.
5. **Accessing a\[7]:**
    - **Virtual Address:** This element is on **VPN 08**, a new page.
    - **TLB Miss:** The TLB does not have the translation for this page.
    - **Page Table Lookup:** The OS fetches the translation from the page table.
    - **TLB Update:** The translation for VPN 08 is added to the TLB.
    - **Array Access:** The program accesses the element in physical memory.
6. **Final Accesses (a[8] and a[9]):**
    - These elements are also on **VPN 08**, so the final accesses result in **TLB hits**.
    - **TLB Hits:** No further page table lookups needed.
    - **Array Access:** The program accesses the elements directly using the TLB.
### TLB Hit/Miss Pattern:
- **Miss:** a[0] (VPN 06)
- **Hit:** a[1] (VPN 06)
- **Hit:** a[2] (VPN 06)
- **Miss:** a[3] (VPN 07)
- **Hit:** a[4] (VPN 07)
- **Hit:** a[5] (VPN 07)
- **Hit:** a[6] (VPN 07)
- **Miss:** a[7] (VPN 08)
- **Hit:** a[8] (VPN 08)
- **Hit:** a[9] (VPN 08)
So, out of the 10 accesses, there are **7 TLB hits** and **3 TLB misses**, giving a **70% hit rate**.
### Key Points:
- **Spatial Locality:** The TLB benefits from spatial locality because multiple consecutive accesses (a[1], a[2], etc.) are on the same page.
- **TLB Misses:** TLB misses only occur when the program accesses a new page (a[0], a[3], a[7]).
- **Improving Performance:** The TLB helps avoid unnecessary page table lookups, significantly improving memory access performance.
-----
## 19.3 - Who Handles The TLB Miss?
### Handling TLB Misses
1. **Hardware-Managed TLB**:
    - In older systems (such as CISC architectures like **Intel x86**), the **hardware** handles the TLB miss entirely. The hardware uses a **page-table base register** to locate the page tables and “walks” the page table to find the required translation.
    - The hardware updates the TLB and retries the instruction, ensuring it hits the TLB on the second attempt.
2. **Software-Managed TLB**:
    - In modern systems (like **MIPS R10k** or **Sun’s SPARC v9**, both RISC architectures), the **OS software** handles the TLB miss.
    - When a TLB miss occurs, the hardware raises an **exception** that:
        - Pauses the current instruction.
        - Raises the privilege level to **kernel mode**.
        - Jumps to a **trap handler**, which is a piece of OS code written to handle the TLB miss.
    - The OS looks up the translation in the page table, updates the TLB, and returns from the trap. The instruction is retried, resulting in a TLB hit.
### Key Details
- **Return from Trap**:
    - In a TLB miss, the OS must **retry the instruction that caused the trap**, so the hardware must save the correct **Program Counter (PC)** when the exception occurs.
    - In contrast, for other system calls, the return-from-trap resumes at the next instruction after the trap.
- **Avoiding Infinite Loops in TLB Miss Handling**:
    - The OS must be careful not to cause an infinite loop of TLB misses.
    - Solutions include:
        - Keeping the TLB miss handler in **physical memory** so it’s not subject to address translation.
        - Reserving some TLB entries for **permanent mappings** to handle TLB miss handling code.
### Advantages of Software-Managed TLBs
- **Flexibility**: The OS can use any data structure for the page table without requiring hardware modifications.
- **Simplicity**: The hardware does less on a miss, simply raising an exception, leaving the more complex task to the OS.
This flexible approach is preferred in modern systems to allow easier OS upgrades and more complex memory management strategies.
-----
## 19.4 - TLB Contents: What’s In There?
### TLB Structure
- A typical **Translation Lookaside Buffer (TLB)** may contain **32, 64, or 128 entries** and is often **fully associative**.
- **Fully associative** means any given translation (mapping of a virtual page number (VPN) to a physical frame number (PFN)) can be located anywhere in the TLB.
- The **hardware searches all TLB entries in parallel** to find the correct translation efficiently.
### TLB Entry Format
- **VPN (Virtual Page Number)**: The virtual address to be translated.
- **PFN (Physical Frame Number)**: The physical memory location corresponding to the VPN.
- **Other bits** that store additional information like:
	- **Valid bit**: Indicates if the TLB entry has a valid translation.
	- **Protection bits**: Controls access types (e.g., read, write, execute) for pages. For instance:
		- **Code pages** might be marked as **read and execute**.
		- **Heap pages** might be marked as **read and write**.
	- Other fields can include an **address-space identifier (ASID)**, a **dirty bit** (tracks modifications), etc.
-----
## 19.5 - TLB Issue: Context Switches
- The **Translation Lookaside Buffer (TLB)** holds virtual-to-physical translations for the currently running process.
- When switching between processes (context switch), these translations become invalid for the next process.
- Example: Process P1 may map its virtual page 10 to physical frame 100, while Process P2 maps its virtual page 10 to physical frame 170. Without proper handling, the TLB cannot differentiate between them.
### Solutions
1. **TLB Flushing**
    - One common approach to solve this issue is to **flush the TLB** on each context switch, clearing all TLB entries.
    - This is done by setting all **valid bits** in the TLB to 0.
    - Drawback: Each process will experience **TLB misses** after every switch, leading to performance overhead.
2. **Address Space Identifier (ASID)**
    - Some hardware systems provide an **Address Space Identifier (ASID)** field in the TLB.
    - The ASID acts as a process identifier, enabling the TLB to differentiate between translations of different processes.
    - This allows the TLB to hold entries from **multiple processes** without conflict, reducing the need to flush the TLB.
    - Example: Process 1 has ASID 1 and Process 2 has ASID 2, so they can both map VPN 10, but with different physical frames and protections.
### Process Sharing
- Two processes can share physical memory pages (e.g., code pages) but map them to different virtual pages in their address spaces.
- Example: Process P1 and P2 both map to physical page 101, but at different virtual page numbers (VPN 10 for P1, VPN 50 for P2).
- Sharing reduces memory overhead by reusing the same physical memory.

- **TLB flushing** ensures correctness on context switches, while using **ASIDs** allows efficient sharing of TLB entries across processes. Shared memory pages further optimize memory usage.
-----
## 19.6 - Issue: Replacement Policy
- Like any cache, the **TLB** has limited entries, so when a new entry is added, an old one must be evicted.
- The **replacement policy** determines which entry to replace, aiming to minimize the **miss rate** and improve **performance**.
### TLB Replacement Policies
- **Least Recently Used (LRU):**
	- Evicts the entry that hasn’t been used for the longest time.
	- **Advantage:** Takes advantage of **temporal locality** in memory access patterns.
	- **Disadvantage:** Can perform poorly in certain cases, such as when a program accesses slightly more pages than the TLB can hold.
- **Random Replacement:**
	- Randomly evicts an entry from the TLB.
	- **Advantage:** Simple to implement and avoids pathological behaviors where more sophisticated policies (like LRU) perform poorly.
-----
## 19.7 - A Real TLB Entry
![[Pasted image 20241004071142.png]]
- The MIPS R4000 uses **software-managed TLBs**, which means the OS handles TLB management via specific instructions.
- It supports a **32-bit virtual address space** with **4KB pages**.
- The TLB entry structure includes fields such as the **VPN** (19 bits), **PFN** (24 bits), and several **control bits**.
### VPN and PFN
- The **VPN** (19 bits) is used for user addresses, as the MIPS system reserves part of the address space for the kernel.
- The **PFN** (24 bits) supports systems with up to **64GB of physical memory**.
### TLB Control Bits
- **Global (G) bit:** Used for globally-shared pages across processes. If set, the **ASID** is ignored.
- **ASID (Address Space Identifier):** An **8-bit** field used to distinguish between different processes' address spaces.
- **Coherence (C) bits:** Control how a page is cached by the hardware.
- **Dirty bit:** Tracks if the page has been written to (important for memory management and swapping).
- **Valid bit:** Indicates if a valid translation exists in the TLB entry.
### TLB Management in MIPS
- **Wired Register:** A special register that allows the OS to reserve TLB entries for its own use, especially during critical operations.
- **TLB Management Instructions:**
	- **TLBP:** Probes the TLB to check if a translation exists.
	- **TLBR:** Reads the contents of a TLB entry into registers.
	- **TLBWI:** Replaces a specific TLB entry.
	- **TLBWR:** Replaces a random TLB entry.
- These instructions are **privileged** to prevent user processes from directly modifying the TLB, which would pose a security risk.
- The **page mask field** allows the MIPS TLB to support multiple page sizes, offering flexibility in memory management.

- The MIPS R4000 TLB is a **software-managed** cache for virtual-to-physical address translations, with control mechanisms to support process isolation, memory coherence, and efficient TLB management through privileged instructions.
-----
