# Reading Materials
[**Paging: Introduction**](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/vm-paging.pdf)
[**Paging: Faster Translations (TLBs)**](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/vm-tlbs.pdf)
[**Paging: Smaller Tables**](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/vm-smalltables.pdf)

----
# Paging: Introduction
### Two Approaches to Space Management
- **Variable-Sized Allocation (Segmentation):**
    - Divides memory into **variable-sized segments** (e.g., code, heap, stack).
    - **Problem:** This approach can lead to **external fragmentation**, making memory allocation harder over time as free space becomes non-contiguous.
- **Fixed-Sized Allocation (Paging):**
    - **Paging** is the second approach that solves space management problems by dividing memory into **fixed-sized pieces**.
    - Paging avoids fragmentation by dividing both virtual and physical memory into **fixed-sized units**.
### Introduction to Paging
- **Basic Idea:**
    - Paging divides a process's **virtual address space** into **fixed-size units** called **pages**.
    - Correspondingly, **physical memory** is divided into **page frames**, each of which can hold a single virtual page.
- **Key Terms:**
    - **Page:** A fixed-sized block of virtual memory.
    - **Page Frame:** A fixed-sized block of physical memory.
### CRUX: How to Virtualize Memory with Pages
- The challenge in paging is to efficiently manage the mapping between **virtual pages** and **physical page frames**.
- The OS must ensure that paging **minimizes overhead** in both **space** (memory usage for tracking pages) and **time** (time taken to translate virtual addresses to physical addresses).
-----
## 18.1 - A Simple Example And Overview
### Paging Process
- **Advantages of Paging:**
    - **Flexibility:** Pages from the virtual address space can be placed in any available page frame in physical memory, without assumptions about memory layout.
    - **Simplified Memory Management:** OS keeps a list of free page frames and allocates any available frames as needed.
- **Page Table:**  A **per-process** data structure that keeps track of where each **virtual page** is located in **physical memory**.
### Address Translation
- **Virtual Address Breakdown:** The virtual address space is 64 bytes (6 bits), so a virtual address is split into two parts:
	- **Virtual Page Number (VPN):** Top 2 bits for the page number.
	- **Offset:** Bottom 4 bits for the location within the page.
- **Example Translation:**
    - Process tries to load data from **virtual address 21**.
    - Virtual address **21** in binary is `010101`:
        - **VPN = 01** (virtual page 1).
        - **Offset = 0101** (the 5th byte in the page).
    1. The **page table** is consulted to translate VPN 1. The page table indicates that **virtual page 1** is in **physical frame 7**.
    2.  Replace VPN 1 with **PFN 7**.
    3. Combine the **PFN** and the **offset**. The result is the physical address **1110101** (decimal 117).
### Key Concepts
- **Page Table Storage:** The OS stores a page table for each process, mapping virtual pages to physical page frames.
- **Page Table Entry (PTE):** Contains information about the mapping between virtual and physical pages.
 - **Benefits of Paging**
	- **No External Fragmentation:** All pages and frames are of equal size, avoiding the fragmentation issue seen with segmentation.
	- **Simplified Allocation:** The OS allocates free page frames as needed without worrying about the size of segments or how memory grows.
----
## 18.2 - Where Are Page Tables Stored?
### Problem with Large Page Tables
- **Page tables** can become **very large**, especially for typical **32-bit address spaces** with 4KB page sizes:
    - Virtual address space splits into:
        - **20-bit Virtual Page Number (VPN)**.
        - **12-bit offset** (for 4KB pages).
    - A **20-bit VPN** means there are **2^20 (1 million) possible translations**.
    - Each **Page Table Entry (PTE)** needs **4 bytes** to store the translation and related information.
    - **Memory requirement per page table**: 4MB.
- **For 100 processes**:
    - The OS would need **400MB of memory** just for page tables.
    - This is a significant amount, even on modern systems with gigabytes of memory.
- Due to their large size, **page tables** are **not stored on-chip** in the **MMU**. Instead, they are stored in **physical memory**, which the OS manages.
- The OS may even **virtualize its own memory**, allowing page tables to be stored in **virtual memory** and even **swapped to disk** when necessary.
### Efficient Page Table Management
- As page tables are large, efficient management is required.
- While **page tables** are stored in **physical memory**, modern systems use various techniques to reduce the overhead of managing and storing page tables (e.g., hierarchical or multi-level page tables, which will be covered in future lessons).
- **Page tables** grow **very large**, especially for large address spaces.
- Storing page tables in memory for **multiple processes** can consume a significant amount of memory, requiring the OS to carefully manage page tables.
- While **modern hardware** doesn't store page tables directly on-chip, it uses **main memory** to store page tables, ensuring efficient address translation while conserving on-chip resources.
----
## 18.3 - What’s Actually In The Page Table?
- The **page table** maps **virtual addresses** (specifically, **virtual page numbers (VPNs)**) to **physical addresses** (specifically, **physical frame numbers (PFNs)**).
- **Simple Structure:** The **linear page table** is the simplest form: an **array** where the **OS indexes by the VPN** to find the **PTE** that holds the translation to the **PFN**.
### Key Contents of Page Table Entries (PTEs)
- **Valid Bit:**
    - Indicates if the translation for a page is valid.
    - Used for **sparse address spaces**: Unused pages (between code, heap, and stack) are marked invalid, avoiding unnecessary memory allocation.
    - If the process tries to access an **invalid** page, it generates a **trap to the OS**, leading to process termination.
- **Protection Bits:**
    - Define whether the page can be **read from**, **written to**, or **executed**.
    - **Access violations** generate a **trap** to the OS.
- **Present Bit:**
    - Indicates if the page is currently in **physical memory** or has been **swapped to disk**.
    - Useful for handling address spaces larger than physical memory.
- **Dirty Bit:** Tracks whether the page has been **modified** since it was loaded into memory.
- **Reference/Accessed Bit:**
    - Tracks whether a page has been **accessed**.
    - Useful in **page replacement** to identify frequently-used pages.
### Example PTE: x86 Architecture
- **x86 Page Table Entry** (PTE) contains:
    - **Present Bit (P)**: Indicates if the page is in memory.
    - **Read/Write Bit (R/W)**: Determines if the page can be written to.
    - **User/Supervisor Bit (U/S)**: Controls if user-mode processes can access the page.
    - **Cache Control Bits (PWT, PCD, PAT, G)**: Determine hardware caching behavior for the page.
    - **Accessed Bit (A)**: Tracks if the page was accessed.
    - **Dirty Bit (D)**: Tracks if the page was modified.
    - **Page Frame Number (PFN)**: Points to the actual location in physical memory.
-----
## 18.4 - Paging: Also Too Slow
- **Translation Steps:**  When accessing memory (e.g., `movl 21, %eax`), the system must:
	1. **Translate the virtual address** (e.g., 21) to a **physical address** (e.g., 117).
	2. Fetch the corresponding **Page Table Entry (PTE)** from the page table.
	3. Use the **Virtual Page Number (VPN)** and the **Page Table Base Register** to locate the PTE.
	4. Combine the **Physical Frame Number (PFN)** and **offset** to generate the final physical address.
### Steps in Translation Process
- **VPN Extraction:**
    - Extract **VPN** from the virtual address using a **VPN mask** and shift operation.
    - For example: Virtual address `21` (binary `010101`) -> VPN = `01` (virtual page 1).
- **Address Calculation:**
    - The **PTE address** is calculated by adding the **VPN** to the **Page Table Base Register**.
    - **PFN** is extracted from the PTE, then **concatenated** with the offset to generate the final physical address.
### Performance Issue
- **Extra Memory Access:**
    - Every memory reference requires one additional memory access to retrieve the page table entry (PTE).
    - This overhead can **slow down** the system significantly, potentially by **a factor of two or more**.
- **Performance Overhead:** Paging requires extra memory references, leading to slower access times.
- **Memory Usage:** Page tables consume a large amount of memory, especially in systems with large address spaces.
-----
## 18.5 - A Memory Trace
```c
int array[1000];
...
for (i = 0; i < 1000; i++)
  array[i] = 0;
```
### Assembly Code Breakdown
- The array initialization compiles into the following assembly instructions:
    - **Instruction 1:** `movl $0x0,(%edi,%eax,4)`  
        Moves the value `0` into the array, with the base address in `%edi` and index `%eax`.
    - **Instruction 2:** `incl %eax`  
        Increments the index (`%eax`).
    - **Instruction 3:** `cmpl $0x03e8,%eax`  
        Compares `%eax` with 1000 (0x03e8 in hex).
    - **Instruction 4:** `jne 1024`  
        Jumps back to the start of the loop if the comparison shows that the loop isn’t finished.
### Virtual and Physical Address Mapping
- The system has a **64KB virtual address space** and **1KB page size**.
- The **code** resides on **virtual page 1** (1024 bytes per page) and maps to **physical frame 4**.
- The **array** spans four virtual pages (VPN 39 to VPN 42), mapping to physical frames (PFN 7 to PFN 10).
### Memory Accesses in Paging
- Each loop iteration involves **multiple memory accesses**:
    - **Instruction Fetch:** Each instruction fetch requires two memory accesses:
        1. **Page Table Access** to find the physical frame.
        2. **Instruction Fetch** from the physical memory.
    - **Array Access (movl):** This requires two more memory accesses:
        1. **Page Table Access** to translate the array’s virtual address.
        2. **Array Access** to store the value in memory.
### Visualization of Memory Accesses
![[pagetable_instruction.png]]
- **Figure** shows the memory accesses for the first five iterations of the loop:
    - **10 memory accesses per iteration:**
        - 4 for instruction fetches.
        - 1 for updating the array.
        - 5 for page table accesses to perform address translation.
### Complexity of Memory Behavior
- Even for a simple loop, the memory behavior becomes complex, involving multiple virtual-to-physical address translations.
- As the loop continues to run, new memory locations (additional array elements) will be accessed, and new page table entries will be involved.
---
# Paging: Faster Translations (TLBs)
- When using paging to support virtual memory, an extra memory lookup is required for each virtual address reference, which can significantly slow down performance. To address this, hardware support in the form of a **Translation Lookaside Buffer (TLB)** is used.
	- **TLB:** A hardware cache that stores recent virtual-to-physical address translations.
	- **How it works:** On each memory reference, the system first checks the TLB for the translation. If the translation is found, the memory access proceeds quickly without consulting the page table in memory.
-----
## 19.1 - TLB Basic Algorithm
In systems with a **hardware-managed TLB** (Translation Lookaside Buffer), the process of virtual address translation is optimized to minimize memory access overhead. 
1. **Extract VPN:** The system extracts the virtual page number (VPN) from the virtual address.
2. **Check TLB:**
    - **TLB hit:** If the TLB holds the translation for the VPN, the page frame number (PFN) is retrieved, and the physical address (PA) is calculated by concatenating the PFN with the offset. This allows direct access to the memory.
    - **TLB miss:** If the TLB does not have the translation, the hardware accesses the page table in memory to find the translation.
3. **Page Table Access (on miss):** When a TLB miss occurs:
    - The hardware consults the page table to retrieve the PFN.
    - If valid, the TLB is updated with this new translation.
4. **Performance:**
    - **TLB hit:** Memory access is quick since the TLB cache is fast and located close to the CPU.
    - **TLB miss:** Extra memory lookups are required to access the page table, which incurs performance costs due to additional memory access.

- The goal is to maximize **TLB hits** to reduce the performance impact of memory accesses. 
-----
## 19.2 - Example: Accessing An Array
### Setup
- **Array Setup:** 
    - You have an array of 10 integers, each 4 bytes in size.
    - The array is located at virtual address **100**.
- **Virtual Address Space:**
    - The system uses an **8-bit virtual address space**, which means the maximum addressable memory is **256 bytes**.
    - **Page size is 16 bytes**, so virtual memory is divided into **16 pages**.
    - Virtual addresses are split into two parts:
        - **VPN (Virtual Page Number):** The top 4 bits specify the page number.
        - **Offset:** The bottom 4 bits specify the location within the page.
### Memory Layout
- **Array Layout on Virtual Pages:**
    - The array begins at **virtual address 100**, which is on page 6 (VPN = 06).
    - Since each page holds 16 bytes, and each integer is 4 bytes, only **3 integers** fit on the first page (a[0], a[1], a[2]).
    - The next integers (a[3] through a[6]) are on **page 7**.
    - The final three integers (a[7] through a[9]) are on **page 8**.
```c
int i, sum = 0;
for (i = 0; i < 10; i++) {
    sum += a[i];
}
```
### Memory Access Breakdown:
When the program runs, it makes several memory accesses. Each access involves translating a virtual address to a physical address using the TLB. Here’s a detailed breakdown:
1. **First Access (a[0]):**
    - **Virtual Address:** 100
    - **VPN:** 06 (from virtual address 100)
    - **TLB Miss:** Since this is the first access to this page, the TLB does not have the translation.
    - **Page Table Lookup:** The OS fetches the translation from the page table and loads it into the TLB.
    - **TLB Update:** The translation for VPN 06 is added to the TLB.
    - **Array Access:** The program accesses the physical memory location mapped by the TLB.
2. **Next Accesses (a[1] and a[2]):**
    - These elements are also on **VPN 06**, so the TLB hit rate is high because the translation for this page is already in the TLB.
    - **TLB Hits:** No need for further page table lookups.
    - **Array Access:** The program directly accesses the data using the TLB translation.
3. **Accessing a\[3]:**
    - **Virtual Address:** This element is on **VPN 07**, a new page.
    - **TLB Miss:** The TLB does not have the translation for this page.
    - **Page Table Lookup:** The OS fetches the translation from the page table.
    - **TLB Update:** The translation for VPN 07 is added to the TLB.
    - **Array Access:** The program accesses the element in physical memory.
4. **Next Accesses (a[4] through a[6]):**
    - These elements are also on **VPN 07**, so subsequent accesses result in **TLB hits**.
    - **TLB Hits:** No further page table lookups needed.
    - **Array Access:** The program accesses the elements directly using the TLB.
5. **Accessing a\[7]:**
    - **Virtual Address:** This element is on **VPN 08**, a new page.
    - **TLB Miss:** The TLB does not have the translation for this page.
    - **Page Table Lookup:** The OS fetches the translation from the page table.
    - **TLB Update:** The translation for VPN 08 is added to the TLB.
    - **Array Access:** The program accesses the element in physical memory.
6. **Final Accesses (a[8] and a[9]):**
    - These elements are also on **VPN 08**, so the final accesses result in **TLB hits**.
    - **TLB Hits:** No further page table lookups needed.
    - **Array Access:** The program accesses the elements directly using the TLB.
### TLB Hit/Miss Pattern:
- **Miss:** a[0] (VPN 06)
- **Hit:** a[1] (VPN 06)
- **Hit:** a[2] (VPN 06)
- **Miss:** a[3] (VPN 07)
- **Hit:** a[4] (VPN 07)
- **Hit:** a[5] (VPN 07)
- **Hit:** a[6] (VPN 07)
- **Miss:** a[7] (VPN 08)
- **Hit:** a[8] (VPN 08)
- **Hit:** a[9] (VPN 08)
So, out of the 10 accesses, there are **7 TLB hits** and **3 TLB misses**, giving a **70% hit rate**.
### Key Points:
- **Spatial Locality:** The TLB benefits from spatial locality because multiple consecutive accesses (a[1], a[2], etc.) are on the same page.
- **TLB Misses:** TLB misses only occur when the program accesses a new page (a[0], a[3], a[7]).
- **Improving Performance:** The TLB helps avoid unnecessary page table lookups, significantly improving memory access performance.
-----
## 19.3 - Who Handles The TLB Miss?
### Handling TLB Misses
1. **Hardware-Managed TLB**:
    - In older systems (such as CISC architectures like **Intel x86**), the **hardware** handles the TLB miss entirely. The hardware uses a **page-table base register** to locate the page tables and “walks” the page table to find the required translation.
    - The hardware updates the TLB and retries the instruction, ensuring it hits the TLB on the second attempt.
2. **Software-Managed TLB**:
    - In modern systems (like **MIPS R10k** or **Sun’s SPARC v9**, both RISC architectures), the **OS software** handles the TLB miss.
    - When a TLB miss occurs, the hardware raises an **exception** that:
        - Pauses the current instruction.
        - Raises the privilege level to **kernel mode**.
        - Jumps to a **trap handler**, which is a piece of OS code written to handle the TLB miss.
    - The OS looks up the translation in the page table, updates the TLB, and returns from the trap. The instruction is retried, resulting in a TLB hit.
### Key Details
- **Return from Trap**:
    - In a TLB miss, the OS must **retry the instruction that caused the trap**, so the hardware must save the correct **Program Counter (PC)** when the exception occurs.
    - In contrast, for other system calls, the return-from-trap resumes at the next instruction after the trap.
- **Avoiding Infinite Loops in TLB Miss Handling**:
    - The OS must be careful not to cause an infinite loop of TLB misses.
    - Solutions include:
        - Keeping the TLB miss handler in **physical memory** so it’s not subject to address translation.
        - Reserving some TLB entries for **permanent mappings** to handle TLB miss handling code.
### Advantages of Software-Managed TLBs
- **Flexibility**: The OS can use any data structure for the page table without requiring hardware modifications.
- **Simplicity**: The hardware does less on a miss, simply raising an exception, leaving the more complex task to the OS.
This flexible approach is preferred in modern systems to allow easier OS upgrades and more complex memory management strategies.
-----
## 19.4 - TLB Contents: What’s In There?
### TLB Structure
- A typical **Translation Lookaside Buffer (TLB)** may contain **32, 64, or 128 entries** and is often **fully associative**.
- **Fully associative** means any given translation (mapping of a virtual page number (VPN) to a physical frame number (PFN)) can be located anywhere in the TLB.
- The **hardware searches all TLB entries in parallel** to find the correct translation efficiently.
### TLB Entry Format
- **VPN (Virtual Page Number)**: The virtual address to be translated.
- **PFN (Physical Frame Number)**: The physical memory location corresponding to the VPN.
- **Other bits** that store additional information like:
	- **Valid bit**: Indicates if the TLB entry has a valid translation.
	- **Protection bits**: Controls access types (e.g., read, write, execute) for pages. For instance:
		- **Code pages** might be marked as **read and execute**.
		- **Heap pages** might be marked as **read and write**.
	- Other fields can include an **address-space identifier (ASID)**, a **dirty bit** (tracks modifications), etc.
-----
## 19.5 - TLB Issue: Context Switches
- The **Translation Lookaside Buffer (TLB)** holds virtual-to-physical translations for the currently running process.
- When switching between processes (context switch), these translations become invalid for the next process.
- Example: Process P1 may map its virtual page 10 to physical frame 100, while Process P2 maps its virtual page 10 to physical frame 170. Without proper handling, the TLB cannot differentiate between them.
### Solutions
1. **TLB Flushing**
    - One common approach to solve this issue is to **flush the TLB** on each context switch, clearing all TLB entries.
    - This is done by setting all **valid bits** in the TLB to 0.
    - Drawback: Each process will experience **TLB misses** after every switch, leading to performance overhead.
2. **Address Space Identifier (ASID)**
    - Some hardware systems provide an **Address Space Identifier (ASID)** field in the TLB.
    - The ASID acts as a process identifier, enabling the TLB to differentiate between translations of different processes.
    - This allows the TLB to hold entries from **multiple processes** without conflict, reducing the need to flush the TLB.
    - Example: Process 1 has ASID 1 and Process 2 has ASID 2, so they can both map VPN 10, but with different physical frames and protections.
### Process Sharing
- Two processes can share physical memory pages (e.g., code pages) but map them to different virtual pages in their address spaces.
- Example: Process P1 and P2 both map to physical page 101, but at different virtual page numbers (VPN 10 for P1, VPN 50 for P2).
- Sharing reduces memory overhead by reusing the same physical memory.

- **TLB flushing** ensures correctness on context switches, while using **ASIDs** allows efficient sharing of TLB entries across processes. Shared memory pages further optimize memory usage.
-----
## 19.6 - Issue: Replacement Policy
- Like any cache, the **TLB** has limited entries, so when a new entry is added, an old one must be evicted.
- The **replacement policy** determines which entry to replace, aiming to minimize the **miss rate** and improve **performance**.
### TLB Replacement Policies
- **Least Recently Used (LRU):**
	- Evicts the entry that hasn’t been used for the longest time.
	- **Advantage:** Takes advantage of **temporal locality** in memory access patterns.
	- **Disadvantage:** Can perform poorly in certain cases, such as when a program accesses slightly more pages than the TLB can hold.
- **Random Replacement:**
	- Randomly evicts an entry from the TLB.
	- **Advantage:** Simple to implement and avoids pathological behaviors where more sophisticated policies (like LRU) perform poorly.
-----
## 19.7 - A Real TLB Entry
![[MIPS TLB Entry.png]]
- The MIPS R4000 uses **software-managed TLBs**, which means the OS handles TLB management via specific instructions.
- It supports a **32-bit virtual address space** with **4KB pages**.
- The TLB entry structure includes fields such as the **VPN** (19 bits), **PFN** (24 bits), and several **control bits**.
### VPN and PFN
- The **VPN** (19 bits) is used for user addresses, as the MIPS system reserves part of the address space for the kernel.
- The **PFN** (24 bits) supports systems with up to **64GB of physical memory**.
### TLB Control Bits
- **Global (G) bit:** Used for globally-shared pages across processes. If set, the **ASID** is ignored.
- **ASID (Address Space Identifier):** An **8-bit** field used to distinguish between different processes' address spaces.
- **Coherence (C) bits:** Control how a page is cached by the hardware.
- **Dirty bit:** Tracks if the page has been written to (important for memory management and swapping).
- **Valid bit:** Indicates if a valid translation exists in the TLB entry.
### TLB Management in MIPS
- **Wired Register:** A special register that allows the OS to reserve TLB entries for its own use, especially during critical operations.
- **TLB Management Instructions:**
	- **TLBP:** Probes the TLB to check if a translation exists.
	- **TLBR:** Reads the contents of a TLB entry into registers.
	- **TLBWI:** Replaces a specific TLB entry.
	- **TLBWR:** Replaces a random TLB entry.
- These instructions are **privileged** to prevent user processes from directly modifying the TLB, which would pose a security risk.
- The **page mask field** allows the MIPS TLB to support multiple page sizes, offering flexibility in memory management.

- The MIPS R4000 TLB is a **software-managed** cache for virtual-to-physical address translations, with control mechanisms to support process isolation, memory coherence, and efficient TLB management through privileged instructions.
-----
# Paging: Smaller Tables

**CRUX: HOW TO MAKE PAGE TABLES SMALLER?**
	Simple array-based page tables (usually called linear page tables) are too big, taking up far too much memory on typical systems. How can we make page tables smaller? What are the key ideas? What inefficiencies arise as a result of these new data structures?

-----
## 20.1 - Simple Solution: Bigger Pages
- One way to reduce the size of the page table is by increasing the **page size**.
- Example: In a **32-bit address space** with **16KB pages**:
	- **VPN** becomes **18 bits**, and the **offset** is **14 bits**.
	- This reduces the number of **page table entries (PTEs)** to **2^18** (262,144), requiring **1MB** per page table (compared to 4MB for 4KB pages).
- This results in a **fourfold reduction** in page table size because of the increased page size.
- **Internal Fragmentation:** The downside of larger pages is **internal fragmentation**, which refers to wasted space within the allocated page.
    - Applications may allocate large pages but use only small portions of them, leading to **inefficient use of memory**.
- **Typical Page Sizes in Systems:** To balance efficiency, most systems use **smaller page sizes**.
        - **4KB pages** in **x86** architecture.
        - **8KB pages** in **SPARCv9** architecture.
-----
## 20.2 - Hybrid Approach: Paging and Segments
- The idea of **combining segmentation and paging** aims to reduce memory overhead by using **smaller page tables**.
- Instead of a single page table for the entire address space, the hybrid approach uses **multiple page tables** — one for each segment (e.g., code, heap, stack).
### Segmentation Review
- In segmentation, each segment (code, heap, stack) has a **base register** (points to the physical location) and a **bounds register** (defines the segment size).
- In the hybrid approach, the **base register** points to the page table of the segment, not the segment itself. The **bounds register** indicates the number of valid pages.
### Address Translation in Hybrid Approach
- The **top bits** of the virtual address determine the segment (e.g., code, heap, or stack).
- Each segment has its **own page table**.
- During address translation, the **base register** for the corresponding segment is used to find the **page table entry (PTE)**, and the **bounds register** ensures memory access is within valid limits.
### Advantages
- **Memory savings**: Only allocated pages have page table entries, avoiding the need to mark unused pages as invalid.
- **Efficient page tables**: Reduces the need for large linear page tables, particularly for sparsely-used address spaces.
### Challenges
- **Segmentation limits flexibility**: For example, large but sparsely-used heaps can still result in **page table waste**.
- **External fragmentation**: While memory is managed in page-sized units, **page tables can vary in size**, leading to external fragmentation and more complex memory allocation.
-----
## 20.3 - Multi-level Page Tables
- A **multi-level page table** transforms the linear page table into a hierarchical structure, allowing for more efficient memory usage by eliminating the need to allocate space for unused or invalid pages.
- This approach is widely used in modern systems (e.g., **x86** architecture) as it significantly reduces memory overhead for large, sparsely used address spaces.
### Structure
- The **page directory** holds entries for each page of the page table. Each entry is called a **Page Directory Entry (PDE)**.
- A **PDE** contains a **valid bit** and a **Page Frame Number (PFN)**. If the PDE is valid, it indicates that at least one **Page Table Entry (PTE)** in that page is valid.
- If the PDE is invalid, no pages from the corresponding page of the page table are allocated, saving memory.
### Benefits of Multi-Level Page Tables
- **Memory efficiency**: Only allocates space for the parts of the address space that are actually used, making it highly suitable for **sparse address spaces**.
- **Manageable memory**: Each part of the page table fits within a single page, making memory allocation and management simpler.
- **Flexible allocation**: Unlike linear page tables, multi-level tables don’t require contiguous memory, making it easier for the OS to allocate page-table pages in fragmented memory.
### Costs
- **Performance trade-off**: On a **TLB miss**, two memory accesses are required to retrieve the correct translation (one for the page directory and one for the PTE), whereas a linear page table only needs one.
- **Increased complexity**: The multi-level page table introduces more complexity in the lookup process, as the hardware or OS must handle the extra level of indirection.
- **Time-Space Trade-Off:**
    - **Space-saving**: The primary advantage is that multi-level page tables reduce memory usage by only allocating what is necessary.
    - **Time cost**: In exchange for saving space, multi-level page tables introduce more **memory lookups** on a TLB miss, making the process slower compared to linear page tables.

### Multi-level Page Example
![[Figure-20.4-AddressSpace.png]]
- **Context and Setup:**
    - In a **16KB address space** with **64-byte pages**, we have a **14-bit virtual address space**: **8 bits for the Virtual Page Number (VPN)** and **6 bits for the offset**.
    ![[AddressBreakdown.png]]
    - A **linear page table** would have **256 entries (2^8)**, one for each VPN. If each Page Table Entry (PTE) is **4 bytes**, the total page table size would be **1KB**.
    - We divide this 1KB page table into **16 pages of 64 bytes** each, where each page holds **16 PTEs**.
- **Multi-Level Page Table Structure:**
	![[Figure-20.5-PageDirectory.png]]
    - The multi-level approach organizes the page table into **two levels**: the **page directory** and **pages of the page table**.
    - The **page directory** has **16 entries**, corresponding to the **16 pages** of the linear page table.
- **Indexing into the Multi-Level Page Table:**
    - The **top 4 bits of the VPN** are used to **index into the page directory** (PDIndex), determining which page of the page table to access.
    - If the **Page Directory Entry (PDE)** is valid, it points to a **page of the page table**. If it's invalid, the memory access is invalid.
    - The **remaining 4 bits of the VPN** are used to **index into the specific page of the page table** (PTIndex) to find the appropriate PTE.
- **Space Savings:**
    - In this example, the address space is divided into regions:
        - **Code segment**: VPNs **0 and 1**
        - **Heap segment**: VPNs **4 and 5**
        - **Stack segment**: VPNs **254 and 255**
    - With a multi-level page table, we only allocate memory for:
        - **Page directory** (1 page)
        - **Two pages of the page table** that contain valid mappings (1 for code and heap, 1 for stack)
    - This results in significant memory savings compared to a full **linear page table**, which would require **16 pages**.
- **Example Translation:**
    - Translate the address **0x3F80** (binary **11 1111 1000 0000**):
        1. Use **top 4 bits (1111)** to index into the **page directory**, selecting the **15th entry**, which points to the **physical address of the page table (PFN 101)**.
        2. Use **next 4 bits (1110)** to index into the **selected page of the page table**, finding the **PTE for VPN 254**, which maps to **physical page 55**.
        3. Concatenate **PFN 55** with the **offset (000000)** to form the final **physical address (0x0DC0)**.
### More Than Two Levels
- **Multi-Level Page Table Basics Recap:**
    - Multi-level page tables break up the page table into smaller pieces to handle large address spaces efficiently.
    - The idea is to make each piece of the page table fit within a page-sized memory unit, reducing wasted memory for unused regions.
- **The Problem with Larger Address Spaces:**
    - For a **30-bit virtual address space** with **512-byte pages**, we have:
        - **21 bits for the Virtual Page Number (VPN)**
        - **9 bits for the offset**
    - With **512-byte pages** and **4-byte PTEs**, each page can fit **128 PTEs**.
    - Therefore, the **page table index** will use the **7 least significant bits** of the VPN.
- **Page Directory Size Issue:**
    - The remaining **14 bits of the VPN** are used for the page directory, giving **16,384 (2^14) entries**.
    - If each Page Directory Entry (PDE) is also **4 bytes**, the page directory would span **128 pages** (16,384 entries * 4 bytes / 512 bytes per page).
    - This means the page directory itself doesn't fit within a single page, complicating our memory management goal.
- **Adding More Levels to the Page Table:**
    - To keep all components of the page table within page-sized units, we **split the page directory** further into multiple pages.
    - We introduce an **additional level**, making the page table a **three-level structure**:
        - **Top-level page directory**: Points to pages of the **second-level page directory**.
        - **Second-level page directory**: Points to pages of the **actual page table**.
        - **Page table**: Contains **Page Table Entries (PTEs)** that map to physical memory.
- **Splitting the Virtual Address:** The virtual address is divided into several parts for indexing each level:
	![[3-level Address.png]]
	- **Top-level page directory index (PD Index 0)**: Uses the highest bits of the VPN.
	- **Second-level page directory index (PD Index 1)**: Uses the next set of bits.
	- **Page table index**: Uses the lower bits of the VPN.
	- **Offset**: The least significant bits specify the exact byte within the page.
- **Translation Process:**
    - **Step 1**: Use the **PD Index 0** to look up an entry in the top-level page directory.
        - If the entry is valid, proceed to the second-level page directory.
    - **Step 2**: Use **PD Index 1** to access the corresponding entry in the second-level page directory.
        - If valid, this entry points to the appropriate page of the page table.
    - **Step 3**: Use the **page table index** to find the PTE, which provides the **physical frame number (PFN)**.
    - **Step 4**: Combine the **PFN** with the **offset** to form the final **physical address**.
- **Advantages and Trade-offs:**
    - **Memory Efficiency**: Only allocate memory for parts of the page table that are in use, which is beneficial for **sparse address spaces**.
    - **Increased Complexity**: Adds extra levels of lookup, which increases the number of memory accesses required on a **TLB miss**.
    - **Time-Space Trade-off**: Multi-level tables reduce memory usage at the cost of additional steps in the address translation process.
-----
## 20.4 - Inverted Page Tables
- Traditional page tables have an entry for each virtual page of a process, requiring a large amount of memory, especially for systems with many processes.
- **Inverted page tables** take a different approach, significantly reducing memory requirements by maintaining a single page table for the entire system.
### Structure of an Inverted Page Table
- Instead of having separate page tables for each process, the inverted page table has **one entry per physical page**.
- Each entry stores:
	- The **process ID** (PID) using that physical page.
	- The **virtual page number (VPN)** of the process that maps to that physical page.
- This structure inherently limits the size of the page table to the number of physical pages, offering significant memory savings.
### Address Translation with Inverted Page Tables
- To translate a virtual address to a physical address, the system needs to find the corresponding entry in the inverted page table.
- This involves **searching** for the matching process ID and VPN in the table.
- A **linear search** would be too slow, so a **hash table** is often used to speed up the lookup process. The hash table maps virtual addresses to entries in the inverted page table.
- **Advantages:**
    - **Significant space savings:** Since the table size is limited to the number of physical pages, it avoids the large memory overhead associated with traditional page tables, especially for large address spaces or many processes.
    - **Simplified memory management:** There is only a single page table to manage.
- **Disadvantages:**
    - **Complex lookups:** Translations can be slower than traditional multi-level page tables because they require searching through the inverted table or using a hash function.
    - **Handling shared memory:** Special mechanisms are needed to manage cases where multiple processes share the same physical memory.
-----
## 20.5 - Swapping the Page Tables to Disk
- Traditionally, page tables are kept in **kernel-owned physical memory** to ensure fast access and reliability.
- Even with optimizations like multi-level page tables and inverted page tables, page tables can still grow **too large to fit into physical memory** entirely.
- Some systems allow **page tables to reside in kernel virtual memory**, enabling them to be managed similarly to other memory-resident data.
### Advantages
- **Flexibility in memory management:** If the page tables are too large to fit in physical memory, parts of them can be **swapped out to disk**.
- **Efficient use of memory:** Only the portions of the page table that are currently needed stay in memory, while other parts can be **paged out** to free up space.
### Disadvantages
- **Performance overhead:** Swapping page tables to disk introduces additional delays, especially during a **TLB miss**, as the required page table entry may not be immediately available.
- **Complexity in implementation:** The system must handle **page faults** for page table entries and **manage kernel memory carefully** to avoid potential deadlocks or excessive paging.
### Implications for System Design
- Storing page tables in kernel virtual memory provides a balance between **memory efficiency** and **performance**, making it suitable for systems with large or dynamic memory requirements.
- Understanding how to **swap pages in and out of memory** effectively is crucial for optimizing this approach.
