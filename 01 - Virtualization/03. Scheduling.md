#  Reading Materials
[Scheduling: Introduction](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/cpu-sched.pdf)
[Scheduling: The Multi-Level Feedback Queue](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/cpu-sched-mlfq.pdf)
[Summary Dialogue on CPU Virtualization](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/cpu-dialogue.pdf)

----
# Scheduling: Introduction
- Scheduling in computer systems has roots in operations management, as both fields aim to efficiently manage tasks or processes.
- The challenge is developing an effective **scheduling policy** that optimizes CPU usage. Key considerations include:
	- **Assumptions:** What are the conditions or constraints in the system?
	- **Metrics:** What criteria (e.g., efficiency, fairness, response time) should the policy optimize?
	- **Approaches:** What strategies have been historically used in early computer systems to guide scheduling decisions?
-----
## 7.1 - Workload Assumptions
- To develop effective scheduling policies, we need to define the **workload**—the characteristics of processes (jobs) running in the system.
- These assumptions simplify the initial exploration of scheduling policies, though they may not reflect real-world scenarios.
### Simplifying Assumptions
- **Assumption 1: Equal Job Run Times**: All jobs in the system are assumed to run for the same amount of time.
- **Assumption 2: Simultaneous Job Arrival**: All jobs are assumed to arrive at the system at the same time.
- **Assumption 3: No Preemption (Run to Completion)**: Once a job starts, it runs to completion without interruption or preemption.
- **Assumption 4: CPU-bound Jobs**: Jobs are assumed to use only the CPU and perform no I/O operations.
- **Assumption 5: Known Job Run Times**: The run-time of each job is known in advance, giving the scheduler complete knowledge of how long each job will take.
### Unrealistic Assumptions
- While these assumptions simplify policy design, they are not realistic in real-world systems.
    - **Example:** Knowing the exact run-time of each job is not feasible, as it would require the scheduler to be omniscient.
- As scheduling policies evolve, these assumptions will be relaxed to better reflect the complexities of real workloads.
- The goal is to eventually develop a **fully-operational scheduling discipline** that can handle more realistic scenarios.
-----
## 7.2 - Scheduling Metrics
- Metrics allow us to evaluate and compare different scheduling policies by providing a way to measure performance.
### Turnaround Time
- **Turnaround time** is the total time a job spends in the system, calculated as the time a job completes minus the time it arrived.
$$T_{turnaround} = T_{completion} − T_{arrival}$$
- **Simplified Case:** We assume all jobs arrive at the same time (Tarrival = 0), the formula simplifies to: $T_{turnaround} = T_{completion}$
- **Primary Metric:** Turnaround time is a **performance metric** that helps us evaluate how quickly jobs complete in a given scheduling policy.
- **Fairness Metric:**
    - Another important metric in scheduling is **fairness**, which ensures that all jobs get a chance to run without significant delay.
    - One example of measuring fairness is **Jain’s Fairness Index**.
- **Trade-off Between Performance and Fairness:** Scheduling policies often have to balance between **performance** and **fairness**.
	- A policy optimized for performance might favor some jobs, leaving others delayed, which reduces fairness.
----
## 7.3 - First in, First Out (FIFO)
- **FIFO (First In, First Out)** or **FCFS (First Come, First Served)** is a basic scheduling algorithm where jobs are executed in the order they arrive.
	- **Simplicity:** Easy to implement and understand.
	- **Order of Execution:** Jobs are processed in the order they enter the system.
### FIFO Scheduling with Equal Job Times
- Three jobs (A, B, and C) arrive at the same time (Tarrival = 0), each running for 10.
    - **Completion Times:**
        - A finishes at 10, B at 20, and C at 30.
    - **Average Turnaround Time:** $T_{turnaround} = (10 + 20 + 30) / 3 = 20$
### FIFO Performance with Varying Job Lengths
- When jobs have different lengths, FIFO can perform poorly.
- A job (A) runs for 100, while jobs B and C run for 10 each.
	- A runs for the full 100, causing B and C to wait in line.
	- **Average Turnaround Time:** $T_{turnaround} = (100 + 110 + 120) / 3 = 110$
- **Problem:**
	- This creates the **convoy effect**, where shorter jobs are delayed by a long-running job, leading to high average turnaround times and poor system performance.
### Drawbacks
- FIFO works well when all jobs have similar execution times.
- It performs poorly when jobs have varying lengths, as longer jobs block shorter jobs from executing.
- **Challenge:** How can we improve scheduling algorithms to handle jobs with different lengths more efficiently and avoid the convoy effect?
-----
## 7.4 - Shortest Job First (SJF)
- **SJF (Shortest Job First)** is a scheduling policy where the shortest job is executed first, followed by the next shortest, and so on.
    - **Goal:** To minimize average turnaround time by prioritizing shorter jobs over longer ones.
### SJF Scheduling to Improve over FIFO
- Three jobs (A, B, and C) arrive at the same time, but A runs for 100, while B and C run for 10 each.
- **SJF Schedule:** Instead of running A first, SJF runs B and C first, significantly reducing the average turnaround time.
- **Results:**
	- Turnaround time with FIFO: 110
	- Turnaround time with SJF: $T_{turnaround} = (10 + 20 + 120) / 3 = 50$
### SJF Performance
- **Optimality:**  Under the assumption that all jobs arrive at the same time, SJF is **optimal** for minimizing average turnaround time.
- **Improvement:** SJF often performs **much better** than FIFO, especially when job lengths vary.
### Challenges When Relaxing Assumptions
- In real-world systems, jobs do not arrive all at once but at different times.
- A arrives at t = 0 and runs for 100, while B and C arrive at t = 10 and each run for 10
- **SJF Problem:** Despite B and C arriving shortly after A, they are forced to wait until A finishes, leading to a **convoy problem** similar to FIFO.
	- **Turnaround Time:** (100 + (110 − 10) + (120 − 10)) / 3 = 103.33
### Limitations of SJF
- **Convoy Problem:** Even with SJF, longer jobs that arrive earlier can delay shorter jobs that arrive later, leading to inefficiencies and high turnaround times.
- **Challenge:** How can a scheduler adapt to jobs arriving at different times while maintaining efficiency? This requires further refinement of scheduling policies.
-----
## 7.5 - Shortest Time-to-Completion First (STCF)
- **STCF (Shortest Time-to-Completion First)**, also known as **Preemptive Shortest Job First (PSJF)**, allows the scheduler to preempt the current job and switch to a new job with the shortest remaining time to completion.
	- **Key Mechanism:** Whenever a new job arrives, the scheduler compares the remaining times of all jobs (including the new one) and runs the job with the least remaining time.
### Problem with Non-Preemptive SJF
- In the **non-preemptive** Shortest Job First (SJF) algorithm, jobs must run to completion once started, which can lead to inefficiencies when shorter jobs arrive after longer ones.
- **Solution:** To improve scheduling efficiency, **preemption** can be introduced to allow the scheduler to interrupt a long-running job when shorter jobs arrive.
### Using STCF to Improve over SJF
- Job A arrives at t = 0 and runs for 100, while jobs B and C arrive at t = 10 and each need to run for 10.
- **With STCF:** When B and C arrive, the scheduler **preempts** job A and runs B and C first. After B and C complete, the scheduler resumes job A.
- **Results:**
    - **Turnaround Time:**
        - Turnaround time with SJF: 103.33
        - Turnaround time with STCF: $T_{turnaround} = (120 − 0) + (20 − 10) + (30 − 10) / 3 = 50$
### Benefits of STCF
- **Optimality:** STCF is **optimal** in terms of minimizing turnaround time, just as SJF is optimal when all jobs arrive at the same time.
- **Preemption:** By allowing preemption, STCF avoids the **convoy effect** seen in non-preemptive schedulers like SJF and FIFO, where long-running jobs block shorter jobs.
- **Improved Efficiency:** STCF ensures that jobs with shorter remaining times are prioritized, improving overall system performance and reducing average turnaround times.
-----
## 7.6 - New Metric: Response Time
- **Response time** is the time from when a job arrives in the system to when it is first scheduled and begins executing.
$$T_{response} = T_{firstrun} − T_{arrival}$$
    - **Example (from Figure 7.5):** All jobs take 10
        - Job A: Arrive at t = 0 -- $0 - 0 = 0$
        - Job B: Arrive at t = 10 -- $10 - 10 = 0$
        - Job C: Arrive at t = 10 -- $20 - 10 = 10$
        - **Average Response Time:** (0 + 0 + 10) / 3 = 3.33
### Limitations of STCF for Response Time
- **Shortest Time-to-Completion First (STCF)** is optimized for **turnaround time** but can perform poorly in terms of response time.
    - **Problem:** When multiple jobs arrive at the same time, the later jobs may experience long delays before they are even scheduled, leading to poor response times.
    - **Example:** If three jobs arrive at once, the third job may have to wait for the first two to complete before it gets scheduled, resulting in a long response time.
- With the rise of interactive systems (e.g., users at terminals), **response time** became an important metric, as users expect quick feedback from the system.
- **User Experience:** A scheduling policy that results in long response times (e.g., waiting 10 for a response) can negatively impact the user experience, making the system feel unresponsive.
### New Challenge for Scheduling
- **Balancing Turnaround and Response Time:** While STCF is great for minimizing **turnaround time**, it is not ideal for **response time**, especially in interactive environments.
    - **Next Step:** The challenge is to design a scheduler that is **sensitive to response time**, providing quick feedback to users while balancing overall system efficiency.
-----
## 7.7 - Round Robin
- **Round-Robin (RR)** is a scheduling algorithm where each job is given a **time slice** (or quantum) to run before the next job in the queue is scheduled. This continues in a cycle until all jobs are complete.
- **Time Slice:** The length of the time slice must be a multiple of the timer interrupt (e.g., if the timer interrupts every 10 milliseconds, time slices could be 10 ms, 20 ms, etc.). RR is sometimes referred to as **time-slicing** due to its method of dividing CPU time equally among jobs.
### RR Scheduling
- Three jobs (A, B, C) arrive at the same time and each needs 5 seconds of CPU time.
- **SJF vs. RR:**
	- In SJF, jobs are run to completion one after the other.
	- In RR with a 1-second time slice, jobs are cycled through quickly.
- **Response Time Comparison:**
	- **RR Response Time:** (0 + 1 + 2) / 3 = 1 second (better for interactivity).
	- **SJF Response Time:** (0 + 5 + 10) / 3 = 5 seconds (worse for interactivity).
### The Importance of Time Slice Length
- **Shorter Time Slices:** Shorter time slices improve **response time** because jobs are cycled through more frequently.
- **Context-Switch Overhead:** If the time slice is too short, frequent context switching increases overhead, reducing overall performance.
	- **Context-Switch Costs:** Besides saving/restoring registers, there are hidden costs such as flushing CPU caches, TLBs, and branch predictors when switching between jobs.
### Round Robin Trade-offs
- **Turnaround Time Performance:** RR tends to perform poorly on **turnaround time** because it stretches out each job by only running them for a short period before switching to the next.
    - **Example:** A, B, and C (each needing 5 seconds) under RR: A finishes at 13, B at 14, C at 15, for an average turnaround time of 14 seconds.
    - **Conclusion:** RR often has worse turnaround time than even FIFO because it delays job completion by dividing CPU time equally across jobs.
- **Fairness:** RR is **fair** because it divides CPU time equally among all jobs on a small time scale.
    - **Trade-off:** Fairness improves response time but negatively impacts turnaround time.
		- Schedulers like SJF and STCF optimize for turnaround time but are bad for response time.
		- RR optimizes for response time but performs poorly on turnaround time.
-----
## KEY CPU VIRTUALIZATION TERMS (MECHANISMS)
- The CPU should support at least two modes of execution: a restricted user mode and a privileged (non-restricted) kernel mode.
- Typical user applications run in user mode, and use a system call to trap into the kernel to request operating system services.
- The trap instruction saves register state carefully, changes the hardware status to kernel mode, and jumps into the OS to a pre-specified destination: the trap table.
- When the OS finishes servicing a system call, it returns to the user program via another special return-from-trap instruction, which reduces privilege and returns control to the instruction after the trap that jumped into the OS.
- The trap tables must be set up by the OS at boot time, and make sure that they cannot be readily modified by user programs. All of this is part of the limited direct execution protocol which runs programs efficiently but without loss of OS control.
- Once a program is running, the OS must use hardware mechanisms to ensure the user program does not run forever, namely the timer interrupt. This approach is a non-cooperative approach to CPU scheduling.
- Sometimes the OS, during a timer interrupt or system call, might wish to switch from running the current process to a different one, a low-level technique known as a context switch.