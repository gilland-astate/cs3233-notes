# Reading Materials
[**The Abstraction: Address Spaces**](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/vm-intro.pdf)
[**Mechanism: Address Translation**](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/vm-mechanism.pdf)
[**Segmentation**](https://pages.cs.wisc.edu/~remzi/Classes/537/Spring2018/Book/vm-segmentation.pdf)

----
# The Abstraction: Address Spaces
- In the early days, building computer systems was simpler because **user expectations were low**.
- Modern challenges in system design arise from **user demands** for "ease of use," "high performance," and "reliability."
-----
## 13.1 - Early Systems
- **Early Memory Model:** In early machines, there was **no abstraction** for memory management. Physical memory was divided between the **operating system** (starting at address 0) and a **single running program**.
- **Simple OS Structure:** The OS was essentially a **library** of routines in memory, and the user’s program occupied the remaining memory space.
- **Low User Expectations:** Users didn't expect complex features from the OS, making life simpler for early OS developers.
-----
## 13.2 - Multiprogramming and Time Sharing
### Era of Multiprogramming
- **Multiprogramming:** Multiple processes are **ready to run** at the same time, and the OS switches between them, improving CPU utilization. This approach was important when machines were **expensive** and maximizing CPU usage was a priority.
- **Time Sharing:** Introduced to improve **interactivity** for users, allowing multiple users to share a machine concurrently and receive timely responses.
    - Time-sharing systems moved away from **batch computing**, addressing slow program-debug cycles that frustrated developers.
- **Initial Approach to Time Sharing:** One method was to give each process full access to memory, then **save and restore** all state, including memory, between processes. However, this approach was **too slow**, especially as memory grew in size.
### Efficient Time Sharing
- **Solution:** Leave multiple processes in memory and switch between them without saving/restoring the entire memory state, making **time sharing more efficient**.
- **Example Setup:** Multiple processes (A, B, and C) reside in **carved-out sections** of physical memory, and the OS switches between them, running one at a time while others wait in the **ready queue**.
- **Memory Protection:** As time sharing grew in popularity, **memory protection** became critical to prevent processes from reading or writing each other’s memory, ensuring system stability and security.
----
## 13.3 - The Address Space
### Address Space
- The **address space** is the OS abstraction that provides each running program with its own **view of memory**. It contains:
	- **Code**: The program's instructions.
	- **Stack**: Used to track function calls, local variables, and parameter passing.
	- **Heap**: Dynamically-allocated memory for user-managed data (e.g., `malloc()` in C, `new` in C++/Java).
- **Example Setup:**
    - In a typical address space (e.g., 16KB), **code** is placed at the top, while the **heap** and **stack** grow from opposite ends (heap grows downward, stack grows upward).
### Physical vs. Virtual Addresses
- The **address space** is a **virtual abstraction**, meaning it doesn’t directly map to **physical memory**
- Each process thinks its memory starts at address 0, but the **actual physical memory location** is different (e.g., process A might start at physical address 320KB).
- **Virtual Addresses:** A **virtual address** is what the program uses to reference memory. The OS, with hardware support, translates this into a **physical address**.
- **Example:**
    - If process A tries to access virtual address 0, the OS maps this request to the corresponding **physical address** (e.g., 320KB).
    - This translation is essential for **efficient memory management** and ensures processes don't interfere with each other’s memory.
- **Memory Virtualization:** The OS **virtualizes memory**, creating the illusion of a large, continuous memory space for each process, while **managing physical memory** efficiently and securely.
-----
## 13.4 - Goals
- The main task of the OS in this context is to **virtualize memory**, creating the illusion of private physical memory for each process.
### Key Goals of Virtual Memory (VM)
1. **Transparency:**
    - The VM system should be **invisible** to the running program.
    - Programs should behave as if they have their own **private memory**, unaware of the OS’s behind-the-scenes memory management.
2. **Efficiency:**
    - The OS should ensure memory virtualization is **time-** and **space-efficient**.
    - The goal is to **minimize performance overhead** and **resource usage** while virtualizing memory.
    - **Hardware support** like Translation Lookaside Buffers (TLBs) will be used to aid time-efficient virtualization.
3. **Protection:**
    - The OS must **protect** processes from one another, ensuring **isolation**.
    - A process should not be able to access or modify memory outside its **address space**, safeguarding the system from faulty or malicious processes.
### Next Steps
- Upcoming chapters will explore **mechanisms** (hardware and OS support) for memory virtualization and relevant **policies** for managing memory, such as:
    - **Free space management**.
    - **Page replacement** when memory runs low.
----
# Mechanism: Address Translation
- Virtualizing the CPU was achieved through **Limited Direct Execution (LDE)**, where the OS only intervenes at key moments (e.g., system calls, timer interrupts), allowing for **efficient control**.
- Similarly, **virtualizing memory** will rely on hardware support while ensuring **efficiency and control**.
### Efficiency in Memory Virtualization
- The OS will use **hardware support** for memory management, initially simple (e.g., a few registers) but growing to include features like **TLBs** (Translation Lookaside Buffers) and **page tables**.
- The goal is to make memory access efficient while **protecting applications** from accessing memory outside their address space.
- **Address Translation** is the key technique where the hardware **transforms each virtual memory address** into a corresponding **physical address**. This occurs on **every memory access** (instruction fetch, load, store).
- The **OS manages the memory**, setting up hardware to ensure proper translations occur and maintaining control over memory allocation.
### Flexibility, Control, and Protection
- Programs should be able to use their **address spaces flexibly**, making the system easier to program.
- The OS must ensure **memory protection** and **isolation**, ensuring that processes cannot access others' memory.
- The ultimate goal is to create the **illusion** that each program has its own **private memory**, hiding the reality that many programs share the same physical memory.
- The OS, with hardware assistance, turns this **complex reality** into a **simple and powerful abstraction** for users.
-----
## 15.1 - Assumptions
- Initial virtualization of memory will start with simple assumptions:
	- **Contiguous Memory**: Each user's address space must be placed contiguously in physical memory.
	- **Small Address Space**: The size of each address space is assumed to be less than the size of physical memory.
	- **Equal Address Spaces**: All address spaces are exactly the same size.
- These assumptions are unrealistic, but will help us begin to explore memory virtualization.
-----
## 15.2 - An Example
### Code Example for Address Translation
```c
// The code loads a value from memory, increments it by 3, 
// and stores it back.
void func() {
  int x = 3000;
  x = x + 3;
}
```
- **Assembly** (x86):
	- `movl 0x0(%ebx), %eax` — load the value from memory into register `eax`.
	- `addl $0x03, %eax` — add 3 to the value in `eax`.
	- `movl %eax, 0x0(%ebx)` — store the updated value back into memory.
###  Process Memory Accesses
- The program executes instructions that interact with memory:
    1. **Fetch instruction** from code section at address 128.
    2. **Load value** from stack (address 15 KB).
    3. **Fetch next instruction** at address 132.
    4. **Modify value** (add 3) in the CPU register.
    5. **Store value** back to memory (stack at 15 KB).
### Virtual vs. Physical Memory
- The program thinks it has a **virtual address space** from 0 to 16 KB.
- However, the OS **relocates** the process in **physical memory** (e.g., starting at 32 KB).
- The OS must create the **illusion** of a continuous virtual memory space while placing processes in available physical memory.
- **Key Problem**: How to make a process believe it’s starting at address 0 in its virtual address space, while it is placed elsewhere in physical memory.
- **Solution**: The OS uses **address translation** to remap the program’s virtual addresses to physical addresses transparently.
-----
## 15.3 - Dynamic (Hardware-based) Relocation
### Base and Limit Registers (Dynamic Relocation)
- First introduced in the late 1950s in early time-sharing systems.
- Uses **two hardware registers**:
    - **Base Register**: Stores the start of the process in physical memory.
    - **Bounds (or Limit) Register**: Sets the size of the address space to ensure a process can only access its own memory.
### Address Translation
- Each program is written as if it is loaded at **address 0** in its **virtual address space**.
- The OS sets the **base register** when the program starts, indicating where the process is loaded in **physical memory**.
- **Address Translation Formula**:
    - `Physical Address = Virtual Address + Base`
    - Example: If the base is set to **32 KB** and the program accesses **address 0**, the physical address is **32 KB**.
- The **bounds register** ensures that processes access only their allocated memory.
- Example: If the bounds register is set to **16 KB**, any address generated by the process that exceeds 16 KB will raise a **fault**.
    - Illegal accesses (e.g., too large or negative addresses) trigger exceptions to protect memory isolation.
- The **Memory Management Unit (MMU)** helps perform these address translations.
- More sophisticated memory-management techniques later build on this simple approach.
### Example Address Translations
- Process address space size: **4 KB** loaded at **16 KB** physical memory.
    - Virtual Address **0** → Physical Address **16 KB**.
    - Virtual Address **1 KB** → Physical Address **17 KB**.
    - Virtual Address **3000** → Physical Address **19.384 KB**.
    - Virtual Address **4400** → **Fault** (out of bounds).
-----
## 15.4 - Hardware Support: A Summary
### Privileged CPU Modes
- **User Mode**: Applications run with limited access to the system, preventing them from performing privileged operations.
- **Kernel (Privileged) Mode**: The OS runs in this mode with full access to all hardware and system resources.
- A **single status bit** indicates the current mode of the CPU.
- **Mode Switching**: Occurs during special events like system calls or interrupts, allowing the CPU to switch from user to kernel mode.
### Base and Bounds Registers
- **Base Register**: Holds the starting physical address of a process’s memory.
- **Bounds Register**: Stores the size or limit of the address space, ensuring that processes cannot access memory beyond their assigned space.
- **Memory Management Unit (MMU)**: Manages base and bounds registers and performs address translations.
### Address Translation
- **Virtual Address to Physical Address**: The CPU adds the base register value to a virtual address to produce the correct physical address.
- The **bounds register** ensures that the address is within the valid range before access is granted.
- Both translation and bounds checking are handled automatically by the **hardware**.
### Privileged Instructions
- The OS needs **privileged instructions** to modify the **base** and **bounds registers** when switching between processes.
- Only in **kernel mode** can these registers be updated to ensure security.
- If a user program tries to modify these registers, the hardware will generate an **exception**.
### Exception Handling
- The CPU must support **exceptions** for:
    - **Out-of-bounds memory access**: When a process tries to access memory outside its bounds.
    - **Privileged instruction violations**: When a user-mode program attempts to execute privileged instructions.
- **Exception Handlers**: The OS provides handlers for these exceptions, which terminate the offending process or take corrective action.
### Hardware Requirements Overview
- **Privileged Mode**: Needed to restrict access to critical operations.
- **Base/Bounds Registers**: Used to translate and protect memory access.
- **Address Translation**: Hardware circuitry checks the validity of memory accesses.
- **Privileged Instructions**: Allow the OS to manage memory and set exception handlers.
- **Exception Raising**: Ensures that illegal operations trigger OS intervention.
-----
## 15.5 - Operating System Issues
### Process Creation
- When a process is created, the OS allocates space for its address space using a **free list** to track available slots in memory.
- For each new process, the OS finds a free slot, marks it as used, and relocates the process into that slot.
### Process Termination
- When a process exits or is terminated, the OS reclaims its memory by putting it back on the free list.
- The OS also cleans up any associated data structures related to the process.
### Context Switching
- During a context switch, the OS must save the current process’s **base** and **bounds** register values in a per-process structure (e.g., Process Control Block or PCB).
- When switching to a new process, the OS restores the base and bounds values for the new process to ensure it runs in its own address space.
- The OS can also move a process’s address space in memory by updating the base register when the process is descheduled.
### Exception Handling
- The OS sets up exception handlers at boot time to manage errors, such as when a process tries to access out-of-bounds memory.
- When a process misbehaves (e.g., illegal memory access), the OS terminates the process and reclaims its resources.
### Hardware/OS Interaction
- Most memory translations are handled by hardware without OS intervention, following the principle of **limited direct execution**.
- The OS becomes involved when exceptions arise or during context switching to maintain memory isolation and control.
-----
# Segmentation
- Previously, entire process address spaces were placed contiguously in memory, causing **waste** between the **stack** and **heap**.
- The **base and bounds** approach relocates processes but still leaves unused memory in physical space.
- **Memory Waste**: Unused space between the stack and heap still consumes physical memory.
- **Limited Flexibility**: Requires the entire address space to fit in memory, which becomes difficult when memory is scarce.
- **How to Support Large Address Spaces Efficiently?** We need a more flexible way to allocate memory without wasting space in unused regions like the stack-heap gap.
-----
## 16.1 - Segmentation: Generalized Base/Bounds    
- **Segmentation** is a memory management technique that divides the address space into **logical segments** (e.g., code, heap, and stack).
- Instead of using a single base and bounds pair, each segment has its own **base** (starting address) and **bounds** (size).
- Segmentation allows the OS to place each segment independently in physical memory, reducing the need to allocate large blocks of contiguous memory, which helps accommodate **sparse address spaces**.
### Segments in the Address Space
- **Logical Segments:**
    - **Code:** Instructions of the program.
    - **Heap:** Dynamically allocated memory (e.g., malloc in C).
    - **Stack:** Function call stack and local variables.
- **Example Setup:**
    - Code segment: Base = 32KB, Size = 2KB
    - Heap segment: Base = 34KB, Size = 3KB
    - Stack segment: Base = 28KB, Size = 2KB
### Translation of Virtual to Physical Addresses
- **Translation Process:** For each memory access, the hardware adds the **base address** to the **offset** (the position within the segment) to compute the **physical address**. The hardware checks if the offset is within bounds to ensure the access is valid.
- **Example 1 (Code Segment):** Accessing virtual address 100 in the code segment:
	- Base (32KB) + Offset (100) = Physical address 32KB + 100 = 32868.
	- The hardware checks the bounds (100 < 2KB) and finds the access valid.
- **Example 2 (Heap Segment):** Accessing virtual address 4200 in the heap segment:
	- The virtual address is 4200, but the heap starts at 4096 (4KB), so the offset is 4200 - 4096 = 104.
	- Base (34KB) + Offset (104) = Physical address 34920.
### Segmentation Faults
- **Out of Bounds Access:** If a program attempts to access memory beyond the bounds of a segment (e.g., accessing an address beyond 3KB in the heap), the hardware detects it as an **illegal memory access**.
    - This triggers a **segmentation fault**, trapping into the OS, and often results in process termination.
## 16.2 - Which Segment Are We Referring To?
### Hardware Identifies the Segment
- **Segment Registers:** During address translation, the hardware needs to know:
	1. **Which segment** the address refers to.
	2. The **offset** within that segment.
- **Explicit Approach (VAX/VMS Example):**
    - The **top few bits** of the virtual address determine the segment, and the **remaining bits** provide the offset.
    - In the example, we have **3 segments** (code, heap, stack), so the top 2 bits of the 14-bit virtual address are used to select the segment.
    - The bottom 12 bits are used as the offset within the selected segment.
### Example Translation (Heap Virtual Address 4200)
- **Virtual Address in Binary:**
    - 4200 (decimal) in binary: `01 0000 0110 1000`
    - The **top 2 bits (01)** indicate the **heap segment**.
    - The **remaining 12 bits** (`0000 0110 1000`) represent the offset, which is **104** in decimal.
- **Translation Process:**
    - The hardware uses the segment (01) to find the **base address** of the heap segment.
    - It adds the **offset (104)** to the base to compute the **physical address**.
    - The bounds check is performed to ensure the offset is within valid limits.
``` c++
 // Get top 2 bits of the 14-bit virtual address
Segment = (VirtualAddress & SEG_MASK) >> SEG_SHIFT;

// Get the offset within the segment
Offset = VirtualAddress & OFFSET_MASK;

// Perform bounds check
if (Offset >= Bounds[Segment])
    RaiseException(PROTECTION_FAULT);
else
    PhysAddr = Base[Segment] + Offset;
    Register = AccessMemory(PhysAddr);
    ```
### Issues with Using Top Bits for Segment Selection
- **Unused Segments:** When using **two bits** for segment selection, we have **four possible segments** but only use three (code, heap, stack), resulting in **wasted address space**.
- **Segment Size Limitation:**
    - Using **2 bits** limits the size of each segment to **4KB**, because the 16KB address space is divided into four 4KB segments.
    - If a segment (e.g., the heap or stack) needs to grow beyond 4KB, the system cannot accommodate it.
### Implicit Approach to Segment Identification
Instead of using the top bits of the address, the **implicit approach** determines the segment based on how the address was generated:
- If the address comes from the **program counter**: It belongs to the **code segment**.
- If the address is derived from the **stack pointer**: It belongs to the **stack segment**.
- Any other address is assumed to be in the **heap** segment.
----
## 16.3 - What About The Stack?
- **Stack Growth:** The **stack** segment grows **backwards** (towards lower addresses), unlike other segments (code, heap) that grow upwards.
    - In the example, the stack is placed at **28KB** in physical memory and grows towards **26KB**.
- **Support for Negative Growth:** The hardware needs extra support to handle segments that grow backwards. It tracks whether a segment grows in the **positive** or **negative** direction.
    - **Segment Registers:** Each segment has a **base** address, a **size**, and a **growth direction** (positive or negative).
	- Example segment register for the stack:
		- Stack: Base = 28KB, Size = 2KB, Growth = 0 (negative direction).
### Translating a Stack Address (Negative Growth)
- **Example: Translating Virtual Address 15KB**
    - Virtual address: **15KB** (hex: 0x3C00, binary: `11 1100 0000 0000`)
    - Top 2 bits (`11`) identify the **stack segment**.
    - The remaining 12 bits represent an **offset** of **3KB** into the segment.
- **Negative Offset Calculation:** Since the segment grows backwards, the hardware calculates the offset by subtracting the **maximum segment size** (4KB in this example) from the offset:
	- **3KB − 4KB = −1KB** (negative offset).
- **Physical Address Translation:** The physical address is calculated by adding the **negative offset** to the **base address**:
	- **Base (28KB) + Offset (−1KB) = 27KB** (physical address).
- **Bounds Check:** The hardware performs a **bounds check** by ensuring the absolute value of the negative offset does not exceed the segment’s current size (2KB in this example).
### Summary of the Process
1. **Identify the segment** from the top bits of the virtual address.
2. **Calculate the offset**: For a segment growing negatively (like the stack), subtract the maximum segment size from the offset to get a negative offset.
3. **Translate the address**: Add the negative offset to the base address to get the physical address.
4. **Bounds check**: Ensure the absolute value of the offset is within the segment’s size.
-----
## 16.4 - Support for Sharing
- **Code Sharing:** Segmentation can support **memory sharing** between processes, particularly for **code segments**. This is still used in modern systems.
    - **Benefit:** By sharing code, the system saves memory while maintaining **process isolation**. Each process still believes it has its own memory space, but the OS secretly shares **read-only code**.
### Hardware Support for Protection
- **Protection Bits:** Additional **protection bits** are added to each segment to control **read, write,** and **execute** permissions for memory segments.
	- **Usage:**
        - Code segments are typically marked as **read-execute**, allowing the same code to be shared by multiple processes without being modified.
        - Other segments like the **heap** and **stack** are marked as **read-write** since they need to be modifiable by processes.
- **Example Segment Register with Protection Bits:**
    - Code Segment: Base = 32KB, Size = 2KB, Growth = Positive, **Protection = Read-Execute**.
    - Heap Segment: Base = 34KB, Size = 3KB, Growth = Positive, **Protection = Read-Write**.
    - Stack Segment: Base = 28KB, Size = 2KB, Growth = Negative, **Protection = Read-Write**.
### Changes to Address Translation with Protection
- **Additional Checks for Access Permissions:** In addition to the previous steps (calculating the segment and offset, checking bounds), the hardware now **checks protection bits**:
	- If a process tries to **write** to a **read-only** segment, or **execute** code from a **non-executable** segment, the hardware raises an exception.
	- The OS then handles the exception and can terminate the process or take corrective action.
- **Algorithm Update:**
    1. **Identify the segment** from the top bits of the virtual address.
    2. **Calculate the offset** within the segment and check if the address is within bounds.
    3. **Check the protection bits**: Ensure the requested access (read, write, execute) is allowed for the segment.
    4. If all checks pass, translate the address and access the physical memory.
    5. If the access violates permissions, raise an **exception** to let the OS handle it.

- **Code Sharing Example:** A code segment with **read-execute** permissions can be mapped into the virtual address spaces of multiple processes. Each process can execute the code, but none can modify it due to the read-only setting.
-----
## 16.5 - Fine-grained vs. Coarse-grained Segmentation
- **Coarse-Grained Segmentation:**
    - Systems like the ones discussed earlier use **a few large segments** (e.g., code, stack, heap).
    - These segments divide the address space into **large, coarse chunks**.
- **Fine-Grained Segmentation:**
    - Some early systems, like **Multics**, used **fine-grained segmentation**, which allowed for a large number of smaller segments.
    - Instead of having just a few large segments, the address space could consist of **many smaller segments**, providing more flexibility.
### Hardware Support for Fine-Grained Segmentation
- **Segment Table:**
    - Fine-grained segmentation requires additional hardware, specifically a **segment table** stored in memory.
    - This table keeps track of **many segments**, enabling systems to support a large number of segments (e.g., thousands of segments).
- **Examples:**
    - Systems like the **Burroughs B5000** supported thousands of segments.
    - The **compiler** would split code and data into separate, smaller segments, which the OS and hardware would manage.
### Benefits of Fine-Grained Segmentation
- **Memory Efficiency:**
    - By having **many smaller segments**, the OS can better track which segments are in use and which are not.
    - This allows the system to utilize **main memory more efficiently**, as it can more accurately allocate memory for active segments.
- **Early Systems:**
    - Systems like **Multics** and the **Burroughs B5000** utilized fine-grained segmentation to optimize memory usage and improve system performance.
    - These systems required advanced hardware support to manage the large number of segments effectively.
-----
## 16.6 - OS Support
### Issues with Segmentation
- **Context Switch** - Saving and Restoring Segment Registers:
    - During a context switch, the OS must save the segment registers of the running process and restore the segment registers of the new process.
    - Each process has its own virtual address space, so the segment registers must be correctly set up for the newly scheduled process.
* ***Segment Growth (or Shrinking):**
    - When a process requests more memory (e.g., via `malloc()`), the **heap segment** may need to grow.
    - If the heap cannot handle the request, a system call (e.g., `sbrk()`) is made to the OS to expand the heap.
    - The OS either grants the request, updates the segment size register, and returns memory to the calling process, or rejects the request if no memory is available.
- **External Fragmentation**: As segments are allocated and deallocated, **holes of free memory** develop between segments, creating **non-contiguous** free spaces.
	- When a large segment needs to be allocated, even if there is enough total free space, it may not be **contiguous**, preventing the allocation from succeeding.
- **Compaction** involves stopping processes, **copying** their segments to contiguous free regions, and updating their segment registers.
    - This rearrangement creates larger blocks of free space but is **expensive** in terms of processor time and memory usage.
### Fragmentation Management Technique
- **Free-List Management Algorithms:** To manage memory and prevent fragmentation, OSes use various **allocation algorithms**:
        - **Best-fit:** Allocates the free block closest in size to the requested segment.
        - **Worst-fit:** Allocates the largest available free block.
        - **First-fit:** Allocates the first available free block that satisfies the request.
        - **Buddy algorithm:** A more complex method that splits memory into smaller blocks in a power-of-two scheme to reduce fragmentation.
- **Key Challenge:**
    - Even with the smartest algorithm, **external fragmentation** will always exist to some degree. The goal is to minimize fragmentation as much as possible.